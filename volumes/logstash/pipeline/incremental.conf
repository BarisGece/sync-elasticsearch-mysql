input {
  jdbc {
    jdbc_driver_library => "/usr/share/logstash/mysql-connector-java-8.0.23.jar"
    jdbc_driver_class => "com.mysql.cj.jdbc.Driver" # "com.mysql.jdbc.Driver" is deprecated
    jdbc_connection_string => "jdbc:mysql://${MYSQL_PATH}:3306/${MYSQL_DATABASE}?zeroDateTimeBehavior=convertToNull"
    jdbc_user => "${MYSQL_USER}"
    jdbc_password => "${MYSQL_PASSWORD}"
    jdbc_paging_enabled => true # This will cause a sql statement to be broken up into multiple queries. Default value is false
    jdbc_page_size => 100000 # JDBC page size. Default value is 100000
    tracking_column => "unix_ts_in_secs"
    use_column_value => true
    tracking_column_type => "numeric"
    sql_log_level => "debug"  # Set Logstash logging level as this
    statement_filepath => "/usr/share/logstash/config/queries/incremental.sql"
    schedule => "*/5 * * * * *"   # Run every 5 seconds
  }
}

filter {
  if [is_deleted] {
    mutate { add_field => { "[@metadata][action]" => "delete" } }
  } else {
    mutate { 
      add_field => { 
        "[@metadata][action]" => "index"
        "l_name" => "%{name}" 
      }
    }
  }

  mutate {
    copy => { "team_id" => "[@metadata][_id]"}
    remove_field => ["team_id", "@version", "unix_ts_in_secs"]
    lowercase => ["l_name"]
  }
}

output {
  # stdout { codec => rubydebug { metadata => true } }
  elasticsearch {
    #hosts => ["${ELASTIC_HOST}"]
    hosts => ["http://elasticsearch:9200"]
    index => "teams"
    user => "elastic"
    password => "${ELASTIC_PASSWORD}"
    ilm_enabled => false # Disabled for AWS ElasticSearch
    action => "%{[@metadata][action]}"
    document_id => "%{[@metadata][_id]}"
    template => "/usr/share/logstash/template/teams.json"
    template_name => "teams"
    template_overwrite => "false"
  }
}
